{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generating_validation_split.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNqoiqW00YxP0eVaqdcxUok",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishandahal/stats453-deep_learning_torch/blob/main/multi_layered_perceptron/Generating_validation_split.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig274w2_l3zc"
      },
      "source": [
        "## Generating validation split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hiS09EcmDdC"
      },
      "source": [
        "- Typical datasets do not have validation set (usually train and test). Validation sets are important for various purposes of model tuning so the test set can remain untouched.\n",
        "- It can be convenient to have a way of splitting the training set into validation set if needed and merge it with training set if needed. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhHsRvtPmysK"
      },
      "source": [
        "## A typical dataset (here: MNIST)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfPAkbWVm4hC"
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXqVIfQJnFZ-",
        "outputId": "5f818936-5f3a-4949-b90d-b8a608235a51"
      },
      "source": [
        "## MNIST DATASET\n",
        "\n",
        "# Note transforms.ToTensor() scales input images \n",
        "# # to 0-1 range\n",
        "\n",
        "train_dataset = datasets.MNIST(root='data',\n",
        "                               train=True,\n",
        "                               transform=transforms.ToTensor(),\n",
        "                               download=True)\n",
        "\n",
        "test_dataset = datasets.MNIST(root='data',\n",
        "                              train=False,\n",
        "                              transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=True,\n",
        "                          num_workers=4)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset,\n",
        "                         batch_size=BATCH_SIZE,\n",
        "                         num_workers=4,\n",
        "                         shuffle=False)\n",
        "\n",
        "# checking dataset\n",
        "\n",
        "for features, labels in train_loader:\n",
        "    print(features.size(), labels.size())\n",
        "    break"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZet2xqxopnL",
        "outputId": "72f759cc-5f7c-40c4-93ce-24a6bd5ec4f2"
      },
      "source": [
        "print(f\"Total number of training examples: {train_dataset.data.size(0)}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of training examples: 60000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2AhynXDq29q"
      },
      "source": [
        "## Subset method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVORzP3wrSJf"
      },
      "source": [
        "Reserving 1000 training examples for Validation and use the remaining 59000 examples for new training set. Note: Subset method automatically shuffle the data prior to each epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB5piYd8rjLn"
      },
      "source": [
        "from torch.utils.data.dataset import Subset"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3HxaOTBrs2g"
      },
      "source": [
        "valid_indices = torch.arange(0, 1000)\n",
        "train_indices = torch.arange(1000, 60000)\n",
        "\n",
        "train_and_valid = datasets.MNIST(root='data',\n",
        "                                 train=True,\n",
        "                                 transform=transforms.ToTensor(),\n",
        "                                 download=True)\n",
        "\n",
        "train_dataset = Subset(train_and_valid, train_indices)\n",
        "valid_dataset = Subset(train_and_valid, valid_indices)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13JcpZwtvg9v"
      },
      "source": [
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          num_workers=4,\n",
        "                          shuffle=True)\n",
        "\n",
        "valid_loader = DataLoader(dataset=valid_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          num_workers=4,\n",
        "                          shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIadGxNfwGp_",
        "outputId": "f6e129f4-6c29-4ebb-8df7-756a03a52a31"
      },
      "source": [
        "## Checking the dataset\n",
        "for images, labels in valid_loader:\n",
        "    print('Image batch dimension: ', images.size())\n",
        "    print('Image label dimension: ', labels.size())\n",
        "    break"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image batch dimension:  torch.Size([64, 1, 28, 28])\n",
            "Image label dimension:  torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kw4Tt-dZwbCF",
        "outputId": "6e809a9e-b8a3-42b5-eff8-20f608c58d81"
      },
      "source": [
        "# Check that shuffling works properly\n",
        "# i.e, label indices should be random order\n",
        "# Also the label order should be different in the second epoch\n",
        "\n",
        "for images, labels in train_loader:\n",
        "    pass\n",
        "print(labels[:10])\n",
        "\n",
        "for images, labels in train_loader:\n",
        "    pass\n",
        "print(labels[:10])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 7, 5, 0, 9, 8, 1, 4, 7])\n",
            "tensor([3, 9, 2, 8, 5, 0, 6, 4, 3, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HDVvUzfxCUa",
        "outputId": "a59f3597-dbc9-45bd-b89b-4c9168987845"
      },
      "source": [
        "## Checking that shuffling works as expected. \n",
        "## fixed random seed should return same labels\n",
        "\n",
        "torch.manual_seed(1)\n",
        "for images, labels in valid_loader:\n",
        "    pass\n",
        "print(labels[:10])\n",
        "\n",
        "torch.manual_seed(1)\n",
        "for images, labels in valid_loader:\n",
        "    pass\n",
        "print(labels[:10])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([5, 1, 7, 8, 5, 0, 3, 4, 7, 7])\n",
            "tensor([5, 1, 7, 8, 5, 0, 3, 4, 7, 7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjVThzJmxu1x"
      },
      "source": [
        "## SubsetRandomSampler Method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oY2nGog6x4E3"
      },
      "source": [
        "Compared to Subset method SubsetRandomSampler method is more convenient solution if we want to assign different transformation methods to training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMIdVrZuyLdh"
      },
      "source": [
        "from torch.utils.data import SubsetRandomSampler"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjjGuX2SyRrR"
      },
      "source": [
        "train_indices = torch.arange(1000, 60000)\n",
        "valid_indices = torch.arange(1000)\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(valid_indices)\n",
        "\n",
        "training_transform = transforms.Compose([transforms.Resize((32, 32)),\n",
        "                                         transforms.RandomCrop((28, 28)),\n",
        "                                         transforms.ToTensor()])\n",
        "\n",
        "valid_transform = transforms.Compose([transforms.Resize((32, 32)),\n",
        "                                      transforms.CenterCrop((28, 28)),\n",
        "                                      transforms.ToTensor()])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='data',\n",
        "                               train=True,\n",
        "                               transform=training_transform,\n",
        "                               download=True)\n",
        "\n",
        "valid_dataset = datasets.MNIST(root='data',\n",
        "                               train=True,\n",
        "                               transform=valid_transform,\n",
        "                               download=False)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          num_workers=4,\n",
        "                          sampler=train_sampler)\n",
        "\n",
        "valid_loader = DataLoader(dataset=valid_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          num_workers=4,\n",
        "                          sampler=valid_sampler)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset,\n",
        "                         batch_size=BATCH_SIZE,\n",
        "                         num_workers=4,\n",
        "                         shuffle=False)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYA6G-t70ywt",
        "outputId": "094ec8bf-bc33-4624-b0fc-c1d4eff1afa7"
      },
      "source": [
        "for images, labels in valid_loader:\n",
        "    print('Image batch dimensions: ', images.shape)\n",
        "    print('Lable batch dimensions: ', labels.shape)\n",
        "    break"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image batch dimensions:  torch.Size([64, 1, 28, 28])\n",
            "Lable batch dimensions:  torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaYCN7WW1Hn2",
        "outputId": "1a606c0b-a7f9-4c84-d7f8-19d540f040a2"
      },
      "source": [
        "## Checking the shuffle\n",
        "for image, labels in valid_loader:\n",
        "    break\n",
        "print(labels[:10])\n",
        "\n",
        "for image, labels in valid_loader:\n",
        "    break\n",
        "print(labels[:10])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([5, 2, 6, 1, 4, 9, 3, 5, 0, 3])\n",
            "tensor([5, 8, 4, 5, 2, 9, 6, 4, 8, 6])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9UGUJp-1fWs",
        "outputId": "549b346a-f978-4532-be08-c4331597c816"
      },
      "source": [
        "## checking for consistency with random seeding\n",
        "torch.manual_seed(0)\n",
        "\n",
        "for image, labels in valid_loader:\n",
        "    break\n",
        "print(labels[:10])\n",
        "\n",
        "torch.manual_seed(0)\n",
        "for image, labels in valid_loader:\n",
        "    break\n",
        "print(labels[:10])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([3, 4, 1, 1, 2, 3, 8, 1, 4, 9])\n",
            "tensor([3, 4, 1, 1, 2, 3, 8, 1, 4, 9])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Igw7yfe1wxL"
      },
      "source": [
        ""
      ],
      "execution_count": 32,
      "outputs": []
    }
  ]
}