{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Onehot Encoding and Cross Entropy.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNcKw3XV/O3SvNwdKgJL8sG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishandahal/stats453-deep_learning_torch/blob/main/Logistic_/Onehot_Encoding_and_Cross_Entropy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_Zq0ljl6CTj"
      },
      "source": [
        "#### **Understanding Onehot Encoding and Cross Entropy in PyTorch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AIAqDRX6hQh"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j15A-Rdi6lQq"
      },
      "source": [
        "#### Onehot Endcoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Og1zNJm6pP6",
        "outputId": "0fa0af0f-fbf0-4cf5-9038-52986bc750d9"
      },
      "source": [
        "def to_onehot(y, num_classes):\n",
        "    y_onehot = torch.zeros(y.size(0), num_classes)\n",
        "    y_onehot.scatter_(1, y.view(-1, 1).long(), 1).float()\n",
        "    return y_onehot\n",
        "\n",
        "y = torch.tensor([0, 1, 2, 2,])\n",
        "\n",
        "y_enc = to_onehot(y, 3)\n",
        "\n",
        "print('One-hot encoding:\\n', y_enc)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "One-hot encoding:\n",
            " tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHwDOgcF7be2"
      },
      "source": [
        "### **Softmax**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejHsJZdN-6jD"
      },
      "source": [
        "Suppose we have some net inputs Z, where each row is one training example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3jYib81BBBR",
        "outputId": "7c288847-d264-4efa-c414-e449ff782bd4"
      },
      "source": [
        "Z = torch.tensor([[-0.3, -0.5, -0.5],\n",
        "                  [-0.4, -0.1, -0.5],\n",
        "                  [-0.3, -0.94, -0.5],\n",
        "                  [-0.99, -0.88, -0.5]])\n",
        "Z"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3000, -0.5000, -0.5000],\n",
              "        [-0.4000, -0.1000, -0.5000],\n",
              "        [-0.3000, -0.9400, -0.5000],\n",
              "        [-0.9900, -0.8800, -0.5000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtducx8RBZQc"
      },
      "source": [
        "Converting the inputs into \"probabilities\" via softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOBORbm1BhaM",
        "outputId": "79d8e264-cf2c-4cb0-aa0e-a2c5e88684af"
      },
      "source": [
        "def softmax(z):\n",
        "    # While summing the dimension changes so using some array manipulation\n",
        "    return (torch.exp(z.t()) / torch.sum(torch.exp(z), dim=1)).t()\n",
        "\n",
        "def softmax2(z):\n",
        "    # Same result as above but keeping dimension helps so no need of array play\n",
        "    return (torch.exp(z) / torch.sum(torch.exp(z), dim=1, keepdim=True))\n",
        "\n",
        "smax = softmax(Z)\n",
        "smax2 = softmax2(Z)\n",
        "\n",
        "print('softmax:\\n', smax)\n",
        "print('softmax2:\\n', smax2)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "softmax:\n",
            " tensor([[0.3792, 0.3104, 0.3104],\n",
            "        [0.3072, 0.4147, 0.2780],\n",
            "        [0.4263, 0.2248, 0.3490],\n",
            "        [0.2668, 0.2978, 0.4354]])\n",
            "softmax2:\n",
            " tensor([[0.3792, 0.3104, 0.3104],\n",
            "        [0.3072, 0.4147, 0.2780],\n",
            "        [0.4263, 0.2248, 0.3490],\n",
            "        [0.2668, 0.2978, 0.4354]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEESDYu0Co2q",
        "outputId": "bcd856c6-5b21-4663-ee59-447b49ba3772"
      },
      "source": [
        ""
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7408, 0.6703, 0.7408, 0.3716],\n",
              "        [0.6065, 0.9048, 0.3906, 0.4148],\n",
              "        [0.6065, 0.6065, 0.6065, 0.6065]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50yKhETiIq-N"
      },
      "source": [
        "Probabilities can be converted back to class labels based on the largest probability in each row"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc6VUT_8J3gl",
        "outputId": "cdd082cd-4e1c-44a2-c104-bfcb7d0452be"
      },
      "source": [
        "def to_classlabel(z):\n",
        "    return torch.argmax(z, dim=1)\n",
        "\n",
        "print('predicted class labels: ', to_classlabel(smax))\n",
        "print('true class labels: ', to_classlabel(y_enc))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted class labels:  tensor([0, 1, 0, 2])\n",
            "true class labels:  tensor([ 0,  1,  2,  2, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vB5DRWefKTYg"
      },
      "source": [
        "### Cross Entropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcTI6Un5K2y0",
        "outputId": "66d5a644-ff44-4cd6-920d-98d0087bab2c"
      },
      "source": [
        "def cross_entropy(softmax, y_target):\n",
        "    return - torch.sum(torch.log(softmax) * (y_target), dim=1)\n",
        "\n",
        "xent = cross_entropy(smax, y_enc)\n",
        "print(\"Cross Entropy: \", xent)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross Entropy:  tensor([0.9698, 0.8801, 1.0527, 0.8314])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2-6F6hHMHFZ"
      },
      "source": [
        "## In PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQOISNkcNCGs"
      },
      "source": [
        "import torch.nn.functional as F"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyKIOzLlNGTI"
      },
      "source": [
        "Note that ```nll_loss``` takes log(softmax) as input:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yxmy2XuYNONh",
        "outputId": "e085c0dc-8c5d-45eb-d9e8-b3d50e26e839"
      },
      "source": [
        "F.nll_loss(torch.log(smax), y, reduction='none')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9698, 0.8801, 1.0527, 0.8314])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GceEfEWNdU9"
      },
      "source": [
        "Note that ```cross_entropy``` takes logits as input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6FC39RnNr30",
        "outputId": "6f5e5101-5fd2-4231-900d-9a159c76363c"
      },
      "source": [
        "F.cross_entropy(Z, y, reduction='none')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9698, 0.8801, 1.0527, 0.8314])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    }
  ]
}